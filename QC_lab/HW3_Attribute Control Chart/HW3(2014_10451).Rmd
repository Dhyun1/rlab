---
title: "HW3(2014_10451)"
author: "2014-10451"
date: "2020년 10월 29일"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# EX 7.4(1)

```{r}
library(dplyr)
library(tidyverse)
table_7e2<-tribble(
  ~n, ~D,
  200,3,
  250,4,
  240,2,
  300,5,
  200,2,
  250,4,
  246,3,
  258,5,
  275,2,
  274,1,
  219,0,
  238,10,
  250,4,
  302,6,
  219,20,
  246,3,
  251,6,
  273,7,
  245,3,
  260,1
)
data<-table_7e2

t_vec<-1:nrow(data)
pbar<-sum(data$D)/sum(data$n)

UCL<-NULL
CL<-NULL
LCL<-NULL
for(i in 1:nrow(data)){
  UCL[i]=min(1,pbar+3*sqrt(pbar*(1-pbar)/data$n[i]))
  CL[i]=pbar
  LCL[i]=max(0,pbar-3*sqrt(pbar*(1-pbar)/data$n[i]))
}
                     
plot(t_vec,data$D/data$n,type="o",lty=1,pch=16,
     xlab="Sample Number",ylab=expression("Sample fraction nonconforming, " ~ hat(p)),mgp=c(2,1,0),
     xlim=c(0,length(t_vec)),ylim=c(0,0.1),cex=0.8)
lines(t_vec,UCL,lty=2,cex=0.8)
lines(t_vec,CL,lty=2,cex=0.8)
lines(t_vec,LCL,lty=2,cex=0.8)
which(data$D/data$n>UCL)
which(data$D/data$n<LCL)
```
주어진 데이터를 tribble로 만들고 각 sample에 대한 p, LCL, UCL을 계산하여 data_CL을 만들었다.
각 number에서 구해진 UCL, LCL에 대하여 각 sample 특성치(=p)가 [LCL,UCL]에 포함되는지 알아본 결과
15번째 데이터가 그것의 UCL을 벗어난 것으로 파악되었다. 따라서 위 preliminary data는 In Control 
상태라고 볼 수 없다.

# EX 7.4(2)

```{r}
pbar_revised<-sum(data$D[-15])/sum(data$n[-15])

UCL<-NULL
CL<-NULL
LCL<-NULL
for(i in 1:nrow(data)){
  UCL[i]=min(1,pbar_revised+3*sqrt(pbar_revised*(1-pbar_revised)/data$n[i]))
  CL[i]=pbar
  LCL[i]=max(0,pbar_revised-3*sqrt(pbar_revised*(1-pbar_revised)/data$n[i]))
}
                     
plot(t_vec,data$D/data$n,type="o",lty=1,pch=16,
     xlab="Sample Number",ylab=expression("Sample fraction nonconforming, " ~ hat(p)),mgp=c(2,1,0),
     xlim=c(0,length(t_vec)),ylim=c(0,0.1),cex=0.8)
lines(t_vec,UCL,lty=2,cex=0.8)
lines(t_vec,CL,lty=2,cex=0.8)
lines(t_vec,LCL,lty=2,cex=0.8)
which(data$D/data$n>UCL)
which(data$D/data$n<LCL)

```
15번째 sample에 특정한 assignable cause가 발견되었다면 그 sample을 고려하지 않고 pbar과 Control Limit을 계산할 수 있다.
기존 plot에 새롭게 계산된 UCL, CL, LCL을 도시한 결과 12번째 sample이 [LCL,UCL]을 벗어남을 확인할 수 있다.
따라서 O.C. 공정이다.

# EX 7.5

```{r}
nbar<-mean(data$n)

UCL<-NULL
CL<-NULL
LCL<-NULL
for(i in 1:nrow(data)){
  UCL[i]=min(1,pbar+3*sqrt(pbar*(1-pbar)/nbar))
  CL[i]=pbar
  LCL[i]=max(0,pbar-3*sqrt(pbar*(1-pbar)/nbar))
}
                     
plot(t_vec,data$D/data$n,type="o",lty=1,pch=16,
     xlab="Sample Number",ylab=expression("Sample fraction nonconforming, " ~ hat(p)),mgp=c(2,1,0),
     xlim=c(0,length(t_vec)),ylim=c(0,0.1),cex=0.8)
lines(t_vec,UCL,lty=2,cex=0.8)
lines(t_vec,CL,lty=2,cex=0.8)
lines(t_vec,LCL,lty=2,cex=0.8)
which(data$D/data$n>UCL)
which(data$D/data$n<LCL)
```
앞선 예제와 동일한 데이터에 대하여, 이번엔 UCL, LCL을 각 sample의 n 값이 아닌 전체 sample의 n 값의 평균인 nbar
을 이용하여 계산한 뒤 plot하였다. variable width CL 방법와 다른 점은 각 sample에 대하여 같은 n 값을 사용하므로
UCL, CL, LCL이 항상 같다. 그리고 variable width CL 방법과 동일하게 15번째 sample이 (LCL,UCL) 구간을 벗어나 공정이
O.C. 상태라고 볼 수 있다는 결과를 제시한다.

# EX 7.6

```{r}
pbar<-sum(data$D)/sum(data$n)

UCL=3
CL=0
LCL=-3
z<-NULL
for(i in 1:nrow(data)){
  z[i]=((data$D[i]/data$n[i])-pbar)/sqrt(pbar*(1-pbar)/data$n[i])
}
                     
plot(t_vec,z,type="o",lty=1,pch=16,
     xlab="Sample Number",ylab=expression(Z[i]),mgp=c(2,1,0),
     xlim=c(0,length(t_vec)),ylim=c(-4,10),cex=0.8)
lines(t_vec,rep(3,nrow(data)),lty=2,cex=0.8)
lines(t_vec,rep(0,nrow(data)),lty=2,cex=0.8)
lines(t_vec,rep(-3,nrow(data)),lty=2,cex=0.8)

which(z>UCL)
which(z<LCL)
```
Standarized z를 이용할 때 UCL=3, CL=0, LCL=-3으로 고정되며 15번째 sample이 Control Limit을 벗어나므로
공정은 O.C 상태이다. z를 사용한 Control Chart를 분석한 결과 앞선 방법과 동일하게 15번째 데이터가 signal하였다.

# EX 7.17(a)

```{r}
n=400
m=30
D=1200
(cbar<-D/m)
(pbar<-D/(m*n))
```
sample size n=400이고, sample number m=30, Total number of defection D=1200일 때
np chart의 모수는 Poisson 분포의 모수 c(=average number of nonconformities on a single inspection unit)
이며 cbar=D/m=40으로 plug-in 할 수 있다.

# EX 7.17(b)

```{r}
UCL<-pbar+3*sqrt(pbar*(1-pbar)/n)
LCL<-pbar-3*sqrt(pbar*(1-pbar)/n)
c(n*LCL,n*UCL)
beta=pbinom(57, size=400, prob=0.15)-pbinom(22, size=400, prob=0.15)
1-beta
```
beta-error=P(D<nUCL|p=0.15)-P(D<=nUCL|p=0.15)
          =P(D<58|p=0.15)-P(D<=22|p=0.15)
          =P(D<=57|p=0.15)-P(D<=22|p=0.15)
          =0.369
따라서 문제의 답은 1-beta-error=0.631이다.

# EX 7.18
```{r}
1/(1-beta)
```
ARL1=1.6이므로 평균적으로 2개의 sample로 chart가 mean shift를 signal할 수 있다.

# EX 7.30(a)
```{r}
n=100
UCL=0.075
CL=0.04
LCL=0.005

p=CL
c(n*LCL,n*UCL)
alpha=1-(ppois(7,lambda=n*p)-ppois(0,lambda=n*p))
alpha
```
1-alpha error=P(D<nUCL|p=0.04)-P(D<=nLCL|p=0.04)
             =P(D<=7|p=0.04)-P(D=0|p=0.04)
D는 원래 binomial을 따르나, 문제에서 요구하는대로
poisson 근사를 하면 D ~ Poisson(c), c=np이다.
위 근사를 거쳐 cdf을 이용해 1-alpha error 값을 구하여
alpha-error을 구할 수 있다.
            
# EX 7.30(b)
```{r}
p1=0.06
beta=ppois(7,lambda=n*p1)-ppois(0,lambda=n*p1)
beta
```
beta error=P(D<nUCL|p=0.06)-P(D<=nLCL|p=0.06)
          =P(D<=7|p=0.06)-P(D=0|p=0.06)
          =0.741
# EX 7.30(c)
```{r}
p1<-seq(0,0.1,by=0.005)
beta_p1<-sapply(p1, function(p1) beta=ppois(7,lambda=n*p1)-ppois(0,lambda=n*p1))
plot(p1,beta_p1)
```
# EX 7.30(d)
```{r}
ARL0=1/alpha
ARL1=1/(1-beta)
c(ARL0,ARL1)
```
앞서구한 alpha, beta 값으로부터 ARL1=15, ARL0=4를 얻는다.

# EX 7.34
```{r}
table_7e9<-tribble(
  ~n,~x,
  18,12,
  18,14,
  24,20,
  22,18,
  22,15,
  22,12,
  20,11,
  20,15,
  20,12,
  20,10,
  18,18,
  18,14,
  18,9,
  20,10,
  20,14,
  20,13,
  24,16,
  24,18,
  22,20,
  21,17
)
data<-table_7e9 
t_vec<-1:nrow(data)
ubar<-sum(data$x)/sum(data$n)

UCL<-NULL
CL<-NULL
LCL<-NULL
for(i in 1:nrow(data)){
  UCL[i]=ubar+3*sqrt(ubar/data$n[i])
  CL[i]=ubar
  LCL[i]=max(0,ubar-3*sqrt(ubar/data$n[i]))
}

plot(t_vec,data$x/data$n,type="o",lty=1,pch=16,
     xlab="Sample Number",ylab=expression(u[i]),mgp=c(2,1,0),
     xlim=c(0,length(t_vec)),ylim=c(0,1.5),cex=0.8)
lines(t_vec,UCL,lty=2,cex=0.8)
lines(t_vec,CL,lty=2,cex=0.8)
lines(t_vec,LCL,lty=2,cex=0.8)
which(data$x/data$n>UCL)
which(data$x/data$n<LCL)
```
x= # of total defection in sample
n= # of inspection units in sample
u= # of nonconformities in inspection units로 정의하자.
sample 특성치는 u를 사용, 각 sample의 u 값에 대응되는 Control Limits을 구하여 plotting한 결과 모든 u 값이 그것의 (LCL, UCL)에 포함되었으므로 공정은 I.C 상태이다.
위 chart에서 Control Limit은 variable width control limits를 사용하였는데 그 이유는 (1) n 값이 sample에 따라 크게 변동하므로 average sample size를 쓰기에는 무리가 있고 (2) standardized z를 쓰면 plot 상에서 sample들의 u 값을 확인할 수 없기 때문이다.

# EX 7.35
```{r}
nbar<-sum(data$n)/nrow(data)
UCL<-NULL
CL<-NULL
LCL<-NULL
for(i in 1:nrow(data)){
  UCL[i]=ubar+3*sqrt(ubar/nbar)
  CL[i]=ubar
  LCL[i]=max(0,ubar-3*sqrt(ubar/nbar))
}

plot(t_vec,data$x/data$n,type="o",lty=1,pch=16,
     xlab="Sample Number",ylab=expression(u[i]),mgp=c(2,1,0),
     xlim=c(0,length(t_vec)),ylim=c(0,1.5),cex=0.8)
lines(t_vec,UCL,lty=2,cex=0.8)
lines(t_vec,CL,lty=2,cex=0.8)
lines(t_vec,LCL,lty=2,cex=0.8)
which(data$x/data$n>UCL)
which(data$x/data$n<LCL)
```
n_i 대신 n의 평균 nbar을 사용하면 UCL, LCL은 모든 sample
에서 동일해지며 plotting 결과 모든 sample이 (LCL,UCL)에 포함되므로 공정은 I.C 상태이다.

# EX 7.36
```{r}
UCL=3
CL=0
LCL=-3
z<-NULL
for(i in 1:nrow(data)){
  z[i]=((data$x[i]/data$n[i])-ubar)/sqrt(ubar/data$n[i])
}
                     
plot(t_vec,z,type="o",lty=1,pch=16,
     xlab="Sample Number",ylab=expression(Z[i]),mgp=c(2,1,0),
     xlim=c(0,length(t_vec)),ylim=c(-4,4),cex=0.8)
lines(t_vec,rep(3,nrow(data)),lty=2,cex=0.8)
lines(t_vec,rep(0,nrow(data)),lty=2,cex=0.8)
lines(t_vec,rep(-3,nrow(data)),lty=2,cex=0.8)
```
standardized z를 사용한 결과 앞선 방법과 동일하게 모든 z 값이 (LCL,UCL) 안에 포함되어 공정이 I.C라고 생각할 수 있다.

# EX 7.52
```{r}
table_7e15<-tribble(
  ~DaysBetween,
  34,
  2,
  8,
  5,
  25,
  33,
  17,
  4,
  10,
  9.25,
  0.50,
  5.25,
  3,
  11,
  2,
  1,
  17,
  45,
  13,
  2,
  7,
  3,
  4,
  11,
  14,
  23,
  33,
  1
)
data<-table_7e15

qqnorm(data$DaysBetween, ylab="Days Between Homicides", xlab="Normal Scores", main="NPP plot") 
qqline(data$DaysBetween)

qqnorm(data$DaysBetween^0.2777, ylab="Days Between Homicides, 0.2777squared", xlab="Normal Scores", main="NPP plot")
qqline(data$DaysBetween^0.2777)

qqnorm(data$DaysBetween^0.25, ylab="Days Between Homicides, 0.25squared", xlab="Normal Scores", main="NPP plot")
qqline(data$DaysBetween^0.25)


xbar<-mean(data$DaysBetween^0.2777)
sigma_hat<-sqrt(sum((data$DaysBetween^0.2777-xbar)^2)/(nrow(data)-1))

UCL<-xbar+3*sigma_hat
CL<-xbar
LCL<-xbar-3*sigma_hat

plot(data$DaysBetween^0.2777,type="b", pch=20, ylab="X bar 0.2777squared", ylim=c(0,4),lty=1)
abline(h=UCL, lty="dotted")
abline(h=CL, lty="dotted")
abline(h=LCL, lty="dotted")

xbar0<-mean(data$DaysBetween^0.25)
sigma_hat0<-sqrt(sum((data$DaysBetween^0.25-xbar)^2)/(nrow(data)-1))

UCL0<-xbar0+3*sigma_hat0
CL0<-xbar0
LCL0<-xbar0-3*sigma_hat0

plot(data$DaysBetween^0.25,type="b", pch=20, ylab="X bar 0.25squared", ylim=c(0,4),lty=1)
abline(h=UCL0, lty="dotted")
abline(h=CL0, lty="dotted")
abline(h=LCL0, lty="dotted")
```
문제에서 따로 분산에 대한 Control Chart는 요구하지 않아 생략하였다. days-between-homicides를 X라 두었을 때 X는 NPP에서 qqline과 비교했을 때 상당히 mismatching함을 알 수 있으며, 따라서 Normality 가정을 만족시키기
위하여 X에 적당한 power을 주어 transformation한 결과 X^0.2777과 X^0.25에 대하여 NPP에서 qqline과 굉장히 유사하였다(따라서 이 transformation을 거친 후 Control Chart를 분석하는 것이 더 통계적으로 맞는 방법임). 
X^0.2777과 X^0.25는 NPP 상에서 큰 차이가 없었고 각각을 이용한 Shewart X bar chart에서도 굉장히 유사한 plot을 보여주었으며 따라서 어떤 transformation을 택하여도 Shewart chart 상에서 statistical stable하다고 볼 수 있다.

# EX 7.63(a)
```{r}
table_7e19<-tribble(
  ~n, ~D,
  1200,8,
  1550,5,
  1000,3,
  950,3,
  2000,6,
  1650,4,
  800,2,
  2150,8,
  1700,6,
  1650,10,
  1000,4,
  1100,6,
  875,5,
  980,8,
  1450,9,
  1500,10,
  1800,11,
  1950,21,
  2200,18,
  1075,8
)
data<-table_7e19
t_vec<-1:length(data$n)
pbar<-sum(data$D)/sum(data$n)

UCL<-NULL
CL<-NULL
LCL<-NULL
for(i in 1:nrow(data)){
  UCL[i]=min(1,pbar+3*sqrt(pbar*(1-pbar)/data$n[i]))
  CL[i]=pbar
  LCL[i]=max(0,pbar-3*sqrt(pbar*(1-pbar)/data$n[i]))
}
                     
plot(t_vec,data$D/data$n,type="o",lty=1,pch=16,
     xlab="Sample Number",ylab=expression("Sample fraction nonconforming, " ~ hat(p)),mgp=c(2,1,0),
     xlim=c(0,length(t_vec)),ylim=c(0,0.02),cex=0.8)
lines(t_vec,UCL,lty=2,cex=0.8)
lines(t_vec,CL,lty=2,cex=0.8)
lines(t_vec,LCL,lty=2,cex=0.8)
which(data$D/data$n>UCL)
which(data$D/data$n<LCL)

```
Variable Sample Size는 크게 3가지 방법이 있는데, 여기서는 Variable Width Control Limits 방법을 택하였다. 그 이유는 다른 방법 중 하나인 Average Sample Size를 사용하기에는 데이터의 n=800 ~ 2200까지 range가 크기 때문에 적합하지 않고, 다른 방법으로 Standardized Z를 사용하는 경우 직접적인 fraction을 plot 상에서 볼 수 없어 해석에 불편함이 있기 때문이다. sample index=18번째에서 sample 특성치가 (LCL,UCL)을 벗어나 이 공정은 statistically unstable(O.C)하다고
볼 수 있다.

# EX 7.63(b)
```{r}
data_z<-data%>%
          mutate(z=(D/n-pbar)/sqrt((1-pbar)*pbar/n))

MR <- abs(data_z$z[2:nrow(data_z)] - data_z$z[1:(nrow(data_z)-1)])
sigma_z<-mean(MR)/1.128

UCL<-NULL
CL<-NULL
LCL<-NULL
for(i in 1:nrow(data)){
  UCL[i]=min(1,pbar+3*sigma_z*sqrt(pbar*(1-pbar)/data$n[i]))
  CL[i]=pbar
  LCL[i]=max(0,pbar-3*sigma_z*sqrt(pbar*(1-pbar)/data$n[i]))
}
                     
plot(t_vec,data$D/data$n,type="o",lty=1,pch=16,
     xlab="Sample Number",ylab=expression("Sample fraction nonconforming, " ~ hat(p)),mgp=c(2,1,0),
     xlim=c(0,length(t_vec)),ylim=c(0,0.02),cex=0.8)
lines(t_vec,UCL,lty=2,cex=0.8)
lines(t_vec,CL,lty=2,cex=0.8)
lines(t_vec,LCL,lty=2,cex=0.8)


```

# EX 7.63(c)
Laney P' chart는 p-chart와 유사하지만 subgroup의 크기와 인접한 sample간 correlation을 고려하여 조정된 variation 추정치를 사용한다는 차이점이 있다. subgroup size n이 크면 UCL은 작아지고 LCL은 커져 Control Limits Interval이 좁아지며(overdispersion : data exhibit more variation than you would expect) 인접한 subgroup sample이 서로 correlated되어 있을 때 Control Limits Interval은 지나치게 넓어지게 되는데(underdispersion) P' chart는 이러한 효과를 줄인다. 이 예제의 경우 subgroup size n이 800 이상으로 매우 커서 overdispersion이 예상되며, 따라서 Laney P' chart를 이용하는 것이 바람직해보인다.
(Reference: 
https://support.minitab.com/en-us/minitab/18/help-and-how-to/quality-and-process-improvement/control-charts/supporting-topics/understanding-attributes-control-charts/overdispersion-and-underdispersion/)


# EX 7.64
```{r}
c=12
UCL=c+3*sqrt(c)
LCL=c-3*sqrt(c)
c(LCL,UCL)

beta=ppois(22,lambda=15)-ppois(1,lambda=1)
ARL1=1/(1-beta)
ARL1
```

X=# of nonconformities on a single inspection unit
라 하면 X ~ Poission(c)
(c=average # of nonconformities on a single unit)
이 때, X의 평균과 분산 모두 c이므로 
UCL=c+3sqrt(c),CL=c, LCL=c-3sqrt(c)이다.
c=12일 때 UCL=22.4, LCL= 1.6(소수점 둘째자리에서 반올림)

beta-error=P(X in (LCL,UCL)|c=15)
          =P(X<22.4|c=15)-P(X<=1.6|c=15)
          =P(X<=22|c=15)-P(X<=1|c=15)
          =0.231
ARL1=1/(1-beta error) => 약 2.
    
# EX 7.65
u-chart에서 사용하는 u=x/n으로, 여기서 n이 모든 sample에
대하여 같다면, u는 c-chart에서 사용하는 c 값에 1/n 일정한 scale로 축소한 값일 뿐이므로 모든 sample에 대하여
u-chart는 c-chart와 scale만 다를뿐 본질적으로 같다.