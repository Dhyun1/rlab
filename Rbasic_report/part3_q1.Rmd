---
title: "326.212 Final Project: Part 3 - Q1"
output: html_document
---

```{r setup, include = FALSE}
knitr::opts_chunk$set(echo = TRUE, error = TRUE, 
                      message = FALSE, warning = FALSE)
```

```{r packages, include = FALSE}
library(tidyverse)
library(tmap)
library(sf)
library(lubridate)
library(corrplot)
library(dplyr)
```

```{r part1 code, include = FALSE}
#getwd()
#dir.create("./data")

info<-read.csv("./data/Measurement_info.csv")
item<-read.csv("./data/Measurement_item_info.csv")
station<-read.csv("./data/Measurement_station_info.csv")

###
data<-info%>%
  full_join(item)%>%
  full_join(station)

###
data = data %>%
  dplyr::mutate(`Pollution level` = ifelse(Average.value<0,NA,ifelse(Average.value<=Good.Blue.,"Good(Blue)",         ifelse(Average.value<=Normal.Green.,"Normal(Green)",                          ifelse(Average.value<=Bad.Yellow.,"Bad(Yellow)",                        ifelse(Average.value<=Very.bad.Red.,"Very bad(Red)",NA))))))

###
data%>%
  dplyr::select(Item.name,Average.value,`Pollution level`)%>%
  head()
```

```{r part2 code, include = FALSE}
var_remove<-c("Station.code","Address","Latitude","Longitude","Item.code",   "Unit.of.measurement","Good.Blue.","Normal.Green.","Bad.Yellow.","Very.bad.Red.")   
index<-sapply(var_remove, function (x) return (which(x==names(data))))

data<-data[,-index]
names(data)

###
type<-sapply(names(data), function (x) return (typeof(data[,x]))) 

var_factor<-names(data)[which(type=="character")]
for (i in 1:length(var_factor)){
    data[,var_factor[i]]<-factor(data[,var_factor[i]])
}
str(data)

###
sum(is.na(data))
sapply(names(data),function(x){
  sum(is.na(data[,x]))
})
###
data%>%
  filter(Average.value<0)%>%
  dplyr::select(Average.value,Instrument.status)%>%
  count(Average.value,Instrument.status)
###
data0<-data%>%
  left_join(item)%>%
  filter(Average.value<=Very.bad.Red.) 
data1<-data%>%
  left_join(item)%>%
  filter(Average.value>Very.bad.Red.)%>%
  mutate(`Pollution level`="Very bad(Red)")

#rbind data0, data1 and select certain columns that question requires.
m<-rbind(data0,data1)%>%
  filter(Average.value>=0)%>%
  dplyr::select("Measurement.date","Average.value","Instrument.status","Item.name","Station.name.district.",`Pollution level`)

data<-m
head(data)
###
#frequency table
table(data$Instrument.status)
#proportion table
table(data$Instrument.status)/nrow(data)
#proportion plot
ggplot(data,aes(x=factor(Instrument.status)))+
  geom_bar(aes(y = (..count..)/sum(..count..)))+
  labs(x="Instrument Status",y="proportion",title="Proportion of Instrument Status") +
  theme_bw()

###
data%>%
  left_join(item)%>%
  filter(Instrument.status==9)%>%
  dplyr::select(Average.value,Very.bad.Red.)%>%
  head()#not that much abnormal data of Average value

data<-data%>%
  mutate(Instrument.status=ifelse(Instrument.status!=0,2,Instrument.status))
#consider all Instrument status with nonzero value(just as definition, means not normal) as abnormal(Instrument status=2)

ggplot(data,aes(x=factor(Instrument.status)))+
  geom_bar(aes(y = (..count..)/sum(..count..)))+
  labs(x="Instrument Status",y="proportion",title="Proportion of Instrument Status(nonzero value processed)") +
  theme_bw()
data_part2q4<-data
###
data%>%
  group_by(Item.name)%>%
  filter(Average.value==max(Average.value))%>%
  dplyr::select(Measurement.date,Station.name.district.)

###
data%>%
  ggplot()+
  geom_bar(aes(x=Item.name, fill=`Pollution level`),position = "fill")+
  labs(title="Levels of pollution in Seoul from 2017 to 2019", x="Item name",y="proportion")+
  theme(plot.title = element_text(hjust = 0))
###
head(data)
###
data%>%
  filter(Item.name=="PM2.5")%>%
  group_by(Station.name.district.)%>%
  summarise(
    PM2.5avg=mean(Average.value)
  )%>%
  filter(rank(PM2.5avg)%in%c(1,25))
###
PM2.5<-data%>%
  filter(Item.name=="PM2.5",Station.name.district.%in%c("Gangbuk-gu","Yeongdeungpo-gu"))%>%
  dplyr::select(Average.value,Station.name.district.)

var.test(PM2.5$Average.value~PM2.5$Station.name.district.)
#p-value<0.05, we say they have non-equal variance

t.test(PM2.5$Average.value~PM2.5$Station.name.district.,alternative="less",
       var.equal=FALSE,alpha=0.05)
###
ymdh<-data.frame(sapply(c("year","month","mday","hour"),function (x){
  get(x)(parse_datetime(as.character(data$Measurement.date)))
}))

data<-cbind(data,ymdh)%>% 
  dplyr::rename(Year=year,Month=month,Day=mday,Hour=hour)
head(data)
###
data%>%
  dplyr::select(Average.value,Item.name,Month)%>%
  filter(Item.name%in%c("PM2.5","PM10"))%>%
  group_by(Month)%>%
  summarise(
    avg25=mean(Average.value[which(Item.name=="PM2.5")]),
    avg10=mean(Average.value[which(Item.name=="PM10")])
  )%>%
  ggplot(aes(x=Month))+
  geom_line(aes(y=avg25),colour="green")+
  geom_line(aes(y=avg10),colour="blue")+
  labs(x="Month",y="Average value",title="Average value of PM2.5(blue), PM10(green)")+
  scale_x_continuous(breaks=seq(1,12,by=1))+
  theme_bw()
###
#dataframe(spread)
data.spread<-data%>%
  dplyr::select(Measurement.date,Station.name.district.,Item.name,Average.value)%>%
  tidyr::spread(key="Item.name",value="Average.value")%>%
  dplyr::select(CO:SO2)
#remove na rows
data.spread<-data.spread%>%
    filter(!is.na(CO),!is.na(SO2),!is.na(PM2.5),!is.na(PM10),!is.na(NO2),!is.na(O3))
head(data.spread)
sum(is.na(data.spread))
###
cor(data.spread)
##
corrplot::corrplot(cor(data.spread))
###
p_1<-data%>%
  filter(Item.name %in% c("NO2","O3"))%>%
  group_by(Month)%>%
  summarise(
    avgN02=mean(Average.value[which(Item.name=="NO2")]),
    avgO3=mean(Average.value[which(Item.name=="O3")])
  )%>%
  ggplot(aes(x=Month))+
  geom_line(aes(y=avgN02),colour="green")+
  geom_line(aes(y=avgO3),colour="blue")+
  labs(x="Month",y="Average value",title="Monthly Average value of NO2(blue), O3(green)",collapse="")+
  scale_x_continuous(breaks=seq(1,12,by=1))+
  theme_bw()

p_2<-data%>%
  filter(Item.name %in% c("NO2","O3"))%>%
  group_by(Hour)%>%
  summarise(
    avgN02=mean(Average.value[which(Item.name=="NO2")]),
    avgO3=mean(Average.value[which(Item.name=="O3")])
  )%>%
  ggplot(aes(x=Hour))+
  geom_line(aes(y=avgN02),colour="green")+
  geom_line(aes(y=avgO3),colour="blue")+
  labs(x="Hour",y="Average value",title="Hourly Average value of NO2(blue), O3(green)")+
  scale_x_continuous(breaks=seq(0,23,by=1))+
  theme_bw()
print(p_1)
print(p_2)
###
```


## 2020-10451 Baek Dae Hyun

## Part 3 - Q1

### [문제 1]

```{r}
korea_shp <- st_read("./data/SIG_202005/SIG.shp")
korea_shp$SIG_KOR_NM <- iconv(korea_shp$SIG_KOR_NM, from = "CP949", to = "UTF-8", 
                              sub = NA, mark = TRUE, toRaw = FALSE)
seoul_shp <- korea_shp %>% filter(str_detect(SIG_CD, "^11"))

data.spread2<-data%>%
  dplyr::select(Measurement.date,Station.name.district.,Item.name,Average.value)%>% #select only data district, item, average value
  tidyr::spread(key="Item.name",value="Average.value")%>% #spread data with key = Item name, value = Average value 
  filter(!is.na(CO),!is.na(SO2),!is.na(PM2.5),!is.na(PM10),!is.na(NO2),!is.na(O3))%>% #remove all rows that has NA 
  mutate(Year=year(parse_datetime(as.character(Measurement.date))),
         Month=month(parse_datetime(as.character(Measurement.date)))) #add date(Year, Month) columns


#summarise Average PM2.5, yearly
PM2.5<-data.spread2%>%
            group_by(Year)%>%
            group_by(Station.name.district., .add=TRUE)%>%
            summarise(
              "Average PM2.5"=mean(PM2.5)
            )%>%
            rename(SIG_ENG_NM=Station.name.district.) #rename in order to join with seoul_shp

sapply(c(2017,2018,2019),function (x){
  map_seoul_PM2.5<-seoul_shp%>%
    left_join(PM2.5)%>%
    filter(Year==x)%>%
    tm_shape() + tm_fill(col="Average PM2.5") + tm_borders()
    print(map_seoul_PM2.5)
    return (NULL)
})

```

 분석을 위해 날짜(시각)과 지역별 오염물질의 양을 데이터로 하는 데이터프레임을 spread로 구현한다. 이는 Part 2에서 한 방법과 매우 유사하며, 여기서 차이점은 Part 2와 달리 오염물질로만 구성된 열에 추가적으로 Year과 Month 열을 추가했다는 것이다.
 코드 간소화를 위해 sapply() 안에 문제에서 요구하는 지도를 print하는 함수를 정의하고 연도에 해당하는 벡터를 넣어 자동으로 print 결과가 출력되게 하였다. 연도별, 지역별 PM2.5 농도의 평균을 계산, Average PM2.5라는 변수를 생성, Average PM2.5과 Year 변수를 seoul_shp에 함께 추가(left_join)한다. 그리고 sapply에 연도를 인자로 넣고, 함수 내에 filter를 연도에 따라 취하도록 하면 코드 한번에 동시에 3개의 plot이 그려지게 된다.
 왼쪽부터 차례로 2017년, 2018년, 2019년 자료이다. 2017년 자료를 보면 색깔이 달라지게 되는 구간 간격이 1인 한편 2018년 2019년은 5이다. 2017년 자료에서 가장 색이 연한 곳의 Average PM2.5는 21~22, 가장 진한 곳은 28~29로 최대 차이가 8이지만 2018년 자료에서는 최대 차이가 15~20에서 30~35로 20이나 차이가 난다. 따라서 2017년 자료는 지역별 Average PM2.5 차이가 작은 편이고, 그것의 큰 차이를 보려면 2018년도와 2019년도 자료에 주목하여야 한다. 2018년도와 2019년도 자료를 보면 5시 방향의 큰 덩어리 , 그리고 지도 중심부로부터 7시 방향으로 이어지는 인접한 3개의 덩어리가 공통적으로 진한 색을 보였다. 그러므로 서울 중심부에서 약간 서쪽에 위치한 인접한 2개의 구, 그리고 그것 중 하나와 인접해 있는 7시 방향, 마지막으로 5시 방향에서 PM2.5의 농도가 높게 나타났다고 볼 수 있다.


### [문제 2]

```{r}
#a function that returns Season with input=Month.
Season<-function(month){
  s = month %/% 3
  if (!(month %in% c(1:12))){
    print("Not available number")
  }
  else if (s==0||s==4){
    return("Winter")
  } 
  else if (s==1){
    return("Spring")
  } 
  else if (s==2){
    return("Summer")
  } 
  else return("Fall")
}

#make df for printing
NO2<-data.spread2%>%
  mutate(season=sapply(Month,Season))%>%
  group_by(season)%>%
  group_by(Station.name.district., .add=TRUE)%>%
  summarise(
    "Average NO2"=mean(NO2)
  )%>% 
  rename(SIG_ENG_NM=Station.name.district.)

#print  
sapply(c("Winter","Spring","Summer","Fall"),function (x){
  map_seoul_NO2<-seoul_shp%>%
    left_join(NO2)%>%
    filter(season==x)%>%
    tm_shape() + tm_fill(breaks = seq(0.01, 0.045, by = 0.005), col="Average NO2") + tm_borders()
    print(map_seoul_NO2)
    return (NULL)
})

```

 먼저 Month를 입력받으면 계절 중 하나를 return하는 Season이라는 함수를 정의하였다. 이 함수는 1부터 12의 자연수 값을 갖는 input 때(만일 아니라면 Not available을 출력하도록 함) 을 3으로 나눈 몫이 0부터 4 중 어느 것인지에 따라 계절을 분류 할 수 있다는 사실을 이용하였다. 그리고 data.spread$Month 값들을 sapply를 이용해 Season 함수에 각각 하나씩 자동으로 들어가 월에 해당하는 계절 값을 반환하도록 하고  mutate하여 하나의 열로 추가하였다. 이 과정을 통하여 계절과 지역에 따른 평균 NO2 양을 나타내는 데이터프레임을 만들게 되었고, 이를 이용하여 또 다시 sapply 함수를 통해 계절별, 지역별 평균 NO2 양을 나타내는 지도를 동시에 출력하였다. 4개의 그림의 범주가 동일하므로 지도 상에서 색깔이 진한 정도는 모든 계절에 걸쳐 동일한 척도로 사용될 수 있다. 
 우선 계절별로 전체적인 NO2 평균 양을 비교하면 여름이 가장 적으며 겨울이 가장 크고, 봄이 가을보다 전체적으로 약간 더 큰 오염물질의 양을 보였다. 
 한편 방위에 따른 NO2 평균 양을 비교하면 중부 지역과 5시, 7시 방향에 위치한 구들은 모든 계절에서 다른 지역보다 더 큰 평균 NO2 값을 보였다. 11시의 1개 구와 12시의 2개 구는 모든 계절에서 다른 지역보다 더 작은 평균 NO2 값을 보였다. 전체적으로 11시와 12시 방향에 위치한 3개의 구를 제외하고는 거의 대부분의 구들은 평균 NO2 값이 모든 계절에 걸쳐 고르게 높은 수준이거나, 상대적으로 낮은 수준이었다가 어떤 한 계절에서 특히 높은 수준을 보이는 경우에 해당한다고 보여진다. 따라서 7시가 오염물질의 양이 계절 통틀어서 전체적으로 제일 많고, 12시 방위가 전체적으로 적은 편이며, 7시와 12시 방위를 제외한 나머지 지역은 전체적으로 평균 ~ 평균 이상의 오염물질 양을 보인다.
 
